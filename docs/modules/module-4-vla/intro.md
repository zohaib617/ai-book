---
sidebar_position: 1
---

# Module 4: Vision-Language-Action (VLA)

This module covers the cutting-edge integration of AI with robotics, focusing on voice commands processed through LLM-based planning and converted to robot actions, completing the end-to-end pipeline.

## Learning Objectives

After completing this module, you will be able to:
- Explain Whisper integration for voice-to-action processing
- Describe cognitive planning using LLMs to generate ROS 2 actions
- Understand the complete autonomous humanoid pipeline

## Module Overview

Voice-language-action represents the cutting-edge integration of AI with robotics. This final module builds on all previous knowledge to show how voice commands can be processed through AI models and converted to specific robot actions, completing the full humanoid robot pipeline.

This module covers:
1. Whisper voice-to-action pipeline
2. LLM cognitive planning â†’ ROS 2 actions
3. Capstone: Autonomous humanoid pipeline